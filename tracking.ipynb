{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f367b1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: unsupported multidisk archive",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Call model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myolo11n.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Print Total number of classes\u001b[39;00m\n\u001b[32m     11\u001b[39m class_list = model.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:83\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRTDETR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model[-\u001b[32m1\u001b[39m]._get_name():  \u001b[38;5;66;03m# if RTDETR head\u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RTDETR\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:153\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:297\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    294\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.task\n\u001b[32m    299\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1501\u001b[39m, in \u001b[36mload_checkpoint\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_checkpoint\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1488\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1489\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1490\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1499\u001b[39m \u001b[33;03m        ckpt (dict): Model checkpoint dictionary.\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1502\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1503\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1448\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1446\u001b[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001b[32m   1447\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m             ckpt = \u001b[43mtorch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\ultralytics\\utils\\patches.py:120\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    118\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\torch\\serialization.py:1491\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1489\u001b[39m orig_position = opened_file.tell()\n\u001b[32m   1490\u001b[39m overall_storage = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m   1492\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[32m   1493\u001b[39m         warnings.warn(\n\u001b[32m   1494\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch.load\u001b[39m\u001b[33m'\u001b[39m\u001b[33m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1495\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m dispatching to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch.jit.load\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (call \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorch.jit.load\u001b[39m\u001b[33m'\u001b[39m\u001b[33m directly to\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1496\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m silence this warning)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1497\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m   1498\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\MEHTAB ALAM\\Desktop\\SIH\\code\\venv\\Lib\\site-packages\\torch\\serialization.py:771\u001b[39m, in \u001b[36m_open_zipfile_reader.__init__\u001b[39m\u001b[34m(self, name_or_buffer)\u001b[39m\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer: Union[\u001b[38;5;28mstr\u001b[39m, IO[\u001b[38;5;28mbytes\u001b[39m]]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: PytorchStreamReader failed reading zip archive: unsupported multidisk archive"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Call model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "\n",
    "# Print Total number of classes\n",
    "class_list = model.names\n",
    "print(class_list)\n",
    "\n",
    "\n",
    "# open the video files\n",
    "cap = cv2.VideoCapture(\"4.mp4\")\n",
    "\n",
    "\n",
    "# Define line positions for counting\n",
    "line_y_red = 350 # Red line position\n",
    "line_y_blue = line_y_red + 50 # Blue line position\n",
    "\n",
    "# Variables to store counting and tracking information\n",
    "counted_ids_red_to_blue = set()\n",
    "counted_ids_blue_to_red = set()\n",
    "\n",
    "# Dictionaries to count objects by class for each direction\n",
    "count_red_to_blue = defaultdict(int) # Moving downwords\n",
    "count_blue_to_red = defaultdict(int) # Moving upwards\n",
    "\n",
    "# State dictionaries to track which line was crossed first\n",
    "crossed_red_first = {}\n",
    "crossed_blue_first = {}\n",
    "\n",
    "\n",
    "# Loop through video frames\n",
    "\n",
    "while cap.isOpened():\n",
    "    print(\"1\")\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO tracking on the frame\n",
    "    results = model.track(frame, persist = True, # bytetrack.yaml\n",
    "                          tracker=\"bytetrack.yaml\", # botsort.yaml\n",
    "                           save = True)\n",
    "    print(results)\n",
    "\n",
    "\n",
    "    # Ensure results are not empty\n",
    "    if results[0].boxes.data is not None:\n",
    "\n",
    "      # Get the detected boxes, their class indices, and track IDs\n",
    "      boxes = results[0].boxes.xyxy.cpu()\n",
    "      track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "      class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "      confidence = results[0].boxes.conf.cpu()\n",
    "\n",
    "      # Draw the line of the each frame\n",
    "      cv2.line(frame, (70, line_y_red), (1200, line_y_red ), (0, 0, 255), 3)\n",
    "      cv2.putText(frame, \"Red Line\", (20, line_y_red - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "      cv2.line(frame, (70, line_y_blue), (1200, line_y_blue), (255, 0, 0), 3)\n",
    "      cv2.putText(frame, \"Blue Line\", (20, line_y_blue - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "      # Loop through each detected object\n",
    "      for box, track_id, class_idx, conf in zip(boxes, track_ids, class_indices, confidence):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "        cx = (x1 + x2) // 2 # Calculate the center point\n",
    "        cy = (y1 + y2) // 2\n",
    "\n",
    "\n",
    "        # Get the class name using the class index\n",
    "        class_name = class_list[class_idx]\n",
    "\n",
    "        # Draw a dot at the center and display the tracking ID and class name\n",
    "        cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "        cv2.putText(frame, f\"ID: {track_id} {class_name} {confidence[-1]:.2f}\", (x1, y1 - 10),\n",
    "        cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 255, 255), 2)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # check if the object crosse the red line\n",
    "        if line_y_red - 3 <= cy <= line_y_red + 3:\n",
    "          # Record that the object crossed the red line\n",
    "          if track_id not in crossed_red_first:\n",
    "            crossed_red_first[track_id] = True\n",
    "\n",
    "        # check if the object crosses the blue line\n",
    "        if line_y_blue - 3 <= cy <= line_y_blue + 3:\n",
    "          # Record that the object crossed the blue line\n",
    "          if track_id not in crossed_blue_first:\n",
    "            crossed_blue_first[track_id] = True\n",
    "\n",
    "\n",
    "        # Counting logic for downward direction (red -> blue)\n",
    "        if track_id in crossed_red_first and track_id not in counted_ids_red_to_blue:\n",
    "          if line_y_blue -5 <= cy <= line_y_blue + 5:\n",
    "            count_red_to_blue[class_name] += 1\n",
    "            counted_ids_red_to_blue.add(track_id)\n",
    "\n",
    "        # Counting logic for upward direction (blue -> red)\n",
    "        if track_id in crossed_blue_first and track_id not in counted_ids_blue_to_red:\n",
    "          if line_y_red -5 <= cy <= line_y_red + 5:\n",
    "            count_blue_to_red[class_name] += 1\n",
    "            counted_ids_blue_to_red.add(track_id)\n",
    "\n",
    "    # Display the counts on the frame\n",
    "    y_offset = 30\n",
    "    for class_name, count in count_red_to_blue.items():\n",
    "      cv2.putText(frame, f\"{class_name} (Down): {count}\", (10, y_offset),\n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "      y_offset += 30\n",
    "\n",
    "    y_offset += 20 # Add spacing for upward counts\n",
    "    for class_name, count in count_blue_to_red.items():\n",
    "      cv2.putText(frame, f\"{class_name} (Up): {count}\", (10, y_offset),\n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0 ,255), 2, cv2.LINE_AA)\n",
    "      y_offset += 30\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"YOLO Object Tracking & Counting\", frame)\n",
    "\n",
    "    # Exit loop if 'ESC' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e06d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
